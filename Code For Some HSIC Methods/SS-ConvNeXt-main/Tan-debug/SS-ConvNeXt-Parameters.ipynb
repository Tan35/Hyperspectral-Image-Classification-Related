{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "48e07c0a",
   "metadata": {},
   "source": [
    "## SS-ConvNeXt\n",
    "\n",
    "![image.png](<https://i.typlog.com/tanxy/8310589926_959279.png>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6bd255c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/txy/anaconda3/envs/txy_pytorch/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "original code from facebook research:\n",
    "https://github.com/facebookresearch/ConvNeXt\n",
    "\"\"\"\n",
    "import pdb\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from timm.models.layers import DropPath, Mlp, PatchEmbed as TimmPatchEmbed\n",
    "from torch import Tensor\n",
    "from typing import Optional, Tuple, Union, Dict\n",
    "import os\n",
    "from einops import rearrange\n",
    "import torchsummary\n",
    "\n",
    "\n",
    "def drop_path(x, drop_prob: float = 0., training: bool = False):\n",
    "\n",
    "    if drop_prob == 0. or not training:\n",
    "        return x\n",
    "    keep_prob = 1 - drop_prob\n",
    "    shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets\n",
    "    random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)\n",
    "    random_tensor.floor_()  # binarize\n",
    "    output = x.div(keep_prob) * random_tensor\n",
    "    return output\n",
    "\n",
    "class DropPath(nn.Module):\n",
    "\n",
    "    def __init__(self, drop_prob=None):\n",
    "        super(DropPath, self).__init__()\n",
    "        self.drop_prob = drop_prob\n",
    "\n",
    "    def forward(self, x):\n",
    "        return drop_path(x, self.drop_prob, self.training)\n",
    "\n",
    "class LayerNorm(nn.Module):\n",
    "    \"\"\"\n",
    "    channel_last shape (batch_size, height, width, channels) Pytorch 默认有官方使用方法\n",
    "    channel_first shape (batch_size, channels, height, width) 需要自己写\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, normalized_shape, eps=1e-6, data_format=\"channels_last\"):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.ones(normalized_shape), requires_grad=True)\n",
    "        self.bias = nn.Parameter(torch.zeros(normalized_shape), requires_grad=True)\n",
    "        self.eps = eps\n",
    "        self.data_format = data_format\n",
    "        if self.data_format not in [\"channels_last\", \"channels_first\"]:\n",
    "            raise ValueError(f\"not support data format '{self.data_format}'\")\n",
    "        self.normalized_shape = (normalized_shape,)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        if self.data_format == \"channels_last\": # 使用 Pytorch 官方使用方法\n",
    "            return F.layer_norm(x, self.normalized_shape, self.weight, self.bias, self.eps)\n",
    "        elif self.data_format == \"channels_first\":\n",
    "            # [batch_size, channels, height, width]\n",
    "            mean = x.mean(1, keepdim=True) # 对 channels 维度求均值\n",
    "            var = (x - mean).pow(2).mean(1, keepdim=True) # 对 channels 维度求方差\n",
    "            x = (x - mean) / torch.sqrt(var + self.eps) # 归一化操作\n",
    "            x = self.weight[:, None, None] * x + self.bias[:, None, None]\n",
    "            return x\n",
    "\n",
    "class SS_ConvNeXt(nn.Module):\n",
    "    def __init__(self, input_shape, num_classes: int = 16, depths: list = None,\n",
    "                 dims: list = None, drop_path_rate: float = 0.5, layer_scale_init_value: float = 1e-6,\n",
    "                 head_init_scale: float = 1.):\n",
    "\n",
    "        super(SS_ConvNeXt, self).__init__()\n",
    "\n",
    "        self.input_shape = input_shape\n",
    "        self.num_classes = num_classes\n",
    "        self.num_layers = len(depths)\n",
    "        self.dims = dims\n",
    "        self.depths = depths\n",
    "        self.downsample_layers1 = nn.ModuleList()  # stem and 3 intermediate downsampling conv layers\n",
    "        self.downsample_layers2 = nn.ModuleList()\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        layer1 = nn.Sequential(nn.Conv2d(input_shape[1], dims[0], kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                               LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\"),\n",
    "                               nn.GELU())\n",
    "        self.layers.append(layer1)\n",
    "        layer2 = nn.Sequential(LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\"),\n",
    "                                       nn.Conv2d(dims[0], dims[1], kernel_size=1, stride=1, padding=0))\n",
    "        self.layers.append(layer2)\n",
    "        layer3 = nn.Sequential(nn.Conv2d(dims[1], dims[2], kernel_size=1, stride=1, padding=0, bias=False),\n",
    "                               LayerNorm(dims[2], eps=1e-6, data_format=\"channels_first\"),\n",
    "                               nn.GELU())\n",
    "        self.layers.append(layer3)\n",
    "        layer4 = nn.Sequential(LayerNorm(dims[2], eps=1e-6, data_format=\"channels_first\"),\n",
    "                                       nn.Conv2d(dims[2], dims[3], kernel_size=1, stride=1, padding=0))\n",
    "        self.layers.append(layer4)\n",
    "        dp_rates = [x.item() for x in torch.linspace(0, drop_path_rate, sum(depths))]\n",
    "\n",
    "        cur = depths[0] + depths[1]\n",
    "        cur1 = sum(depths) - depths[3]\n",
    "\n",
    "        self.spatial_conv = nn.ModuleList()\n",
    "\n",
    "        self.spectral_conv = nn.ModuleList()\n",
    "        for i in range(2):\n",
    "            spatial_stage = nn.Sequential(*[spatial_ConvBlock(dim=dims[i], drop_rate=dp_rates[j] if i == 0 else dp_rates[j+depths[0]], layer_scale_init_value=layer_scale_init_value)\n",
    "                                       for j in range(depths[i])])\n",
    "\n",
    "            self.spatial_conv.append(spatial_stage)\n",
    "            spectral_stage = nn.Sequential(*[spectral_ConvBlock(dim=dims[i+2], drop_rate=dp_rates[cur+j] if i+2 == 2 else dp_rates[cur1+j], layer_scale_init_value=layer_scale_init_value)\n",
    "                                       for j in range(depths[i+2])])\n",
    "\n",
    "            self.spectral_conv.append(spectral_stage)\n",
    "\n",
    "        self.ln1 = LayerNorm(dims[2], eps=1e-6, data_format=\"channels_first\")\n",
    "        self.ln2 = LayerNorm(dims[0], eps=1e-6, data_format=\"channels_first\")\n",
    "        self.ln3 = LayerNorm(dims[3], eps=1e-6, data_format=\"channels_first\")\n",
    "\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc = nn.Linear(dims[-1], num_classes)\n",
    "        self.activate = nn.GELU()   # GELU\n",
    "\n",
    "        self.apply(self.initialize_weights)\n",
    "        self.fc.weight.data.mul_(head_init_scale)\n",
    "        self.fc.bias.data.mul_(head_init_scale)\n",
    "\n",
    "    def initialize_weights(self, module):\n",
    "        if isinstance(module, nn.Conv2d):\n",
    "            nn.init.kaiming_normal_(module.weight.data, mode='fan_out')\n",
    "            # nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.BatchNorm2d):\n",
    "            module.weight.data.fill_(1)\n",
    "            module.bias.data.zero_()\n",
    "        elif isinstance(module, nn.Linear):\n",
    "            nn.init.trunc_normal_(module.weight, std=.02)\n",
    "            nn.init.constant_(module.bias, 0)\n",
    "            if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "                nn.init.constant_(module.bias, 0)\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            nn.init.constant_(module.bias, 0)\n",
    "            nn.init.constant_(module.weight, 1.0)\n",
    "\n",
    "    def _forward_spa_cvNet(self,x):\n",
    "        for i in range(2):\n",
    "            x = self.layers[i](x)\n",
    "            x = self.spatial_conv[i](x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _forward_spe_cvNet(self,x):\n",
    "        for i in range(2):\n",
    "            x = self.layers[i+2](x)\n",
    "            x = self.spectral_conv[i](x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self._forward_spa_cvNet(x)\n",
    "        x = self._forward_spe_cvNet(x)\n",
    "        x = self.activate(self.ln3(x))\n",
    "        x = F.adaptive_avg_pool2d(x, output_size=1)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class spatial_ConvBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, drop_rate=0.5, layer_scale_init_value=1e-6):\n",
    "        super().__init__()\n",
    "        self.dwconv = nn.Conv2d(dim, dim, kernel_size=3, stride=1, padding=1, groups=dim, bias=True)  # depthwise conv\n",
    "        self.norm = LayerNorm(dim, eps=1e-6, data_format=\"channels_last\")\n",
    "        self.ln1 = LayerNorm(dim, eps=1e-6, data_format=\"channels_first\")\n",
    "        self.pwconv1 = nn.Linear(dim, 4 * dim)  # pointwise/1x1 convs, implemented with linear layers\n",
    "        self.act = nn.GELU()\n",
    "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim,)),\n",
    "                                  requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "        self.drop_path = DropPath(drop_rate) if drop_rate > 0. else nn.Identity()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        shortcut = x\n",
    "        x = self.dwconv(x)\n",
    "        x = x.permute(0, 2, 3, 1)  # [N, C, H, W] -> [N, H, W, C]\n",
    "        x = self.norm(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        if self.gamma is not None:\n",
    "            x = self.gamma * x\n",
    "        x = x.permute(0, 3, 1, 2)  # [N, H, W, C] -> [N, C, H, W]\n",
    "\n",
    "        x = shortcut + self.drop_path(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class spectral_ConvBlock(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, drop_rate=0.5, layer_scale_init_value=1e-6):\n",
    "        super().__init__()\n",
    "        self.dwconv = nn.Conv2d(dim, dim, kernel_size=1, stride=1, padding=0, bias=True)  # depthwise conv\n",
    "        self.norm = LayerNorm(dim, eps=1e-6, data_format=\"channels_last\")\n",
    "        self.ln = LayerNorm(dim, eps=1e-6, data_format=\"channels_first\")\n",
    "        self.pwconv1 = nn.Linear(dim, 4 * dim)  # pointwise/1x1 convs, implemented with linear layers\n",
    "        self.act = nn.GELU()\n",
    "        self.pwconv2 = nn.Linear(4 * dim, dim)\n",
    "        self.gamma = nn.Parameter(layer_scale_init_value * torch.ones((dim,)),\n",
    "                                  requires_grad=True) if layer_scale_init_value > 0 else None\n",
    "        self.drop_path = DropPath(drop_rate) if drop_rate > 0. else nn.Identity()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        shortcut = x\n",
    "        x = self.dwconv(x)\n",
    "        x = x.permute(0, 2, 3, 1)  # [N, C, H, W] -> [N, H, W, C]\n",
    "        x = self.norm(x)\n",
    "        x = self.pwconv1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.pwconv2(x)\n",
    "        if self.gamma is not None:\n",
    "            x = self.gamma * x\n",
    "        x = x.permute(0, 3, 1, 2)  # [N, H, W, C] -> [N, C, H, W]\n",
    "\n",
    "        x = shortcut + self.drop_path(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "690dca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [16, 200, 9, 9]\n",
    "n_classes = 16\n",
    "depths = [3, 3, 9, 3]\n",
    "dims = [64, 128, 256, 512]\n",
    "model = SS_ConvNeXt(input_shape=input_shape, num_classes=n_classes, depths=depths, dims=dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92ec6531",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1             [-1, 64, 9, 9]          12,800\n",
      "         LayerNorm-2             [-1, 64, 9, 9]             128\n",
      "              GELU-3             [-1, 64, 9, 9]               0\n",
      "            Conv2d-4             [-1, 64, 9, 9]             640\n",
      "         LayerNorm-5             [-1, 9, 9, 64]             128\n",
      "            Linear-6            [-1, 9, 9, 256]          16,640\n",
      "              GELU-7            [-1, 9, 9, 256]               0\n",
      "            Linear-8             [-1, 9, 9, 64]          16,448\n",
      "          Identity-9             [-1, 64, 9, 9]               0\n",
      "spatial_ConvBlock-10             [-1, 64, 9, 9]               0\n",
      "           Conv2d-11             [-1, 64, 9, 9]             640\n",
      "        LayerNorm-12             [-1, 9, 9, 64]             128\n",
      "           Linear-13            [-1, 9, 9, 256]          16,640\n",
      "             GELU-14            [-1, 9, 9, 256]               0\n",
      "           Linear-15             [-1, 9, 9, 64]          16,448\n",
      "         DropPath-16             [-1, 64, 9, 9]               0\n",
      "spatial_ConvBlock-17             [-1, 64, 9, 9]               0\n",
      "           Conv2d-18             [-1, 64, 9, 9]             640\n",
      "        LayerNorm-19             [-1, 9, 9, 64]             128\n",
      "           Linear-20            [-1, 9, 9, 256]          16,640\n",
      "             GELU-21            [-1, 9, 9, 256]               0\n",
      "           Linear-22             [-1, 9, 9, 64]          16,448\n",
      "         DropPath-23             [-1, 64, 9, 9]               0\n",
      "spatial_ConvBlock-24             [-1, 64, 9, 9]               0\n",
      "        LayerNorm-25             [-1, 64, 9, 9]             128\n",
      "           Conv2d-26            [-1, 128, 9, 9]           8,320\n",
      "           Conv2d-27            [-1, 128, 9, 9]           1,280\n",
      "        LayerNorm-28            [-1, 9, 9, 128]             256\n",
      "           Linear-29            [-1, 9, 9, 512]          66,048\n",
      "             GELU-30            [-1, 9, 9, 512]               0\n",
      "           Linear-31            [-1, 9, 9, 128]          65,664\n",
      "         DropPath-32            [-1, 128, 9, 9]               0\n",
      "spatial_ConvBlock-33            [-1, 128, 9, 9]               0\n",
      "           Conv2d-34            [-1, 128, 9, 9]           1,280\n",
      "        LayerNorm-35            [-1, 9, 9, 128]             256\n",
      "           Linear-36            [-1, 9, 9, 512]          66,048\n",
      "             GELU-37            [-1, 9, 9, 512]               0\n",
      "           Linear-38            [-1, 9, 9, 128]          65,664\n",
      "         DropPath-39            [-1, 128, 9, 9]               0\n",
      "spatial_ConvBlock-40            [-1, 128, 9, 9]               0\n",
      "           Conv2d-41            [-1, 128, 9, 9]           1,280\n",
      "        LayerNorm-42            [-1, 9, 9, 128]             256\n",
      "           Linear-43            [-1, 9, 9, 512]          66,048\n",
      "             GELU-44            [-1, 9, 9, 512]               0\n",
      "           Linear-45            [-1, 9, 9, 128]          65,664\n",
      "         DropPath-46            [-1, 128, 9, 9]               0\n",
      "spatial_ConvBlock-47            [-1, 128, 9, 9]               0\n",
      "           Conv2d-48            [-1, 256, 9, 9]          32,768\n",
      "        LayerNorm-49            [-1, 256, 9, 9]             512\n",
      "             GELU-50            [-1, 256, 9, 9]               0\n",
      "           Conv2d-51            [-1, 256, 9, 9]          65,792\n",
      "        LayerNorm-52            [-1, 9, 9, 256]             512\n",
      "           Linear-53           [-1, 9, 9, 1024]         263,168\n",
      "             GELU-54           [-1, 9, 9, 1024]               0\n",
      "           Linear-55            [-1, 9, 9, 256]         262,400\n",
      "         DropPath-56            [-1, 256, 9, 9]               0\n",
      "spectral_ConvBlock-57            [-1, 256, 9, 9]               0\n",
      "           Conv2d-58            [-1, 256, 9, 9]          65,792\n",
      "        LayerNorm-59            [-1, 9, 9, 256]             512\n",
      "           Linear-60           [-1, 9, 9, 1024]         263,168\n",
      "             GELU-61           [-1, 9, 9, 1024]               0\n",
      "           Linear-62            [-1, 9, 9, 256]         262,400\n",
      "         DropPath-63            [-1, 256, 9, 9]               0\n",
      "spectral_ConvBlock-64            [-1, 256, 9, 9]               0\n",
      "           Conv2d-65            [-1, 256, 9, 9]          65,792\n",
      "        LayerNorm-66            [-1, 9, 9, 256]             512\n",
      "           Linear-67           [-1, 9, 9, 1024]         263,168\n",
      "             GELU-68           [-1, 9, 9, 1024]               0\n",
      "           Linear-69            [-1, 9, 9, 256]         262,400\n",
      "         DropPath-70            [-1, 256, 9, 9]               0\n",
      "spectral_ConvBlock-71            [-1, 256, 9, 9]               0\n",
      "           Conv2d-72            [-1, 256, 9, 9]          65,792\n",
      "        LayerNorm-73            [-1, 9, 9, 256]             512\n",
      "           Linear-74           [-1, 9, 9, 1024]         263,168\n",
      "             GELU-75           [-1, 9, 9, 1024]               0\n",
      "           Linear-76            [-1, 9, 9, 256]         262,400\n",
      "         DropPath-77            [-1, 256, 9, 9]               0\n",
      "spectral_ConvBlock-78            [-1, 256, 9, 9]               0\n",
      "           Conv2d-79            [-1, 256, 9, 9]          65,792\n",
      "        LayerNorm-80            [-1, 9, 9, 256]             512\n",
      "           Linear-81           [-1, 9, 9, 1024]         263,168\n",
      "             GELU-82           [-1, 9, 9, 1024]               0\n",
      "           Linear-83            [-1, 9, 9, 256]         262,400\n",
      "         DropPath-84            [-1, 256, 9, 9]               0\n",
      "spectral_ConvBlock-85            [-1, 256, 9, 9]               0\n",
      "           Conv2d-86            [-1, 256, 9, 9]          65,792\n",
      "        LayerNorm-87            [-1, 9, 9, 256]             512\n",
      "           Linear-88           [-1, 9, 9, 1024]         263,168\n",
      "             GELU-89           [-1, 9, 9, 1024]               0\n",
      "           Linear-90            [-1, 9, 9, 256]         262,400\n",
      "         DropPath-91            [-1, 256, 9, 9]               0\n",
      "spectral_ConvBlock-92            [-1, 256, 9, 9]               0\n",
      "           Conv2d-93            [-1, 256, 9, 9]          65,792\n",
      "        LayerNorm-94            [-1, 9, 9, 256]             512\n",
      "           Linear-95           [-1, 9, 9, 1024]         263,168\n",
      "             GELU-96           [-1, 9, 9, 1024]               0\n",
      "           Linear-97            [-1, 9, 9, 256]         262,400\n",
      "         DropPath-98            [-1, 256, 9, 9]               0\n",
      "spectral_ConvBlock-99            [-1, 256, 9, 9]               0\n",
      "          Conv2d-100            [-1, 256, 9, 9]          65,792\n",
      "       LayerNorm-101            [-1, 9, 9, 256]             512\n",
      "          Linear-102           [-1, 9, 9, 1024]         263,168\n",
      "            GELU-103           [-1, 9, 9, 1024]               0\n",
      "          Linear-104            [-1, 9, 9, 256]         262,400\n",
      "        DropPath-105            [-1, 256, 9, 9]               0\n",
      "spectral_ConvBlock-106            [-1, 256, 9, 9]               0\n",
      "          Conv2d-107            [-1, 256, 9, 9]          65,792\n",
      "       LayerNorm-108            [-1, 9, 9, 256]             512\n",
      "          Linear-109           [-1, 9, 9, 1024]         263,168\n",
      "            GELU-110           [-1, 9, 9, 1024]               0\n",
      "          Linear-111            [-1, 9, 9, 256]         262,400\n",
      "        DropPath-112            [-1, 256, 9, 9]               0\n",
      "spectral_ConvBlock-113            [-1, 256, 9, 9]               0\n",
      "       LayerNorm-114            [-1, 256, 9, 9]             512\n",
      "          Conv2d-115            [-1, 512, 9, 9]         131,584\n",
      "          Conv2d-116            [-1, 512, 9, 9]         262,656\n",
      "       LayerNorm-117            [-1, 9, 9, 512]           1,024\n",
      "          Linear-118           [-1, 9, 9, 2048]       1,050,624\n",
      "            GELU-119           [-1, 9, 9, 2048]               0\n",
      "          Linear-120            [-1, 9, 9, 512]       1,049,088\n",
      "        DropPath-121            [-1, 512, 9, 9]               0\n",
      "spectral_ConvBlock-122            [-1, 512, 9, 9]               0\n",
      "          Conv2d-123            [-1, 512, 9, 9]         262,656\n",
      "       LayerNorm-124            [-1, 9, 9, 512]           1,024\n",
      "          Linear-125           [-1, 9, 9, 2048]       1,050,624\n",
      "            GELU-126           [-1, 9, 9, 2048]               0\n",
      "          Linear-127            [-1, 9, 9, 512]       1,049,088\n",
      "        DropPath-128            [-1, 512, 9, 9]               0\n",
      "spectral_ConvBlock-129            [-1, 512, 9, 9]               0\n",
      "          Conv2d-130            [-1, 512, 9, 9]         262,656\n",
      "       LayerNorm-131            [-1, 9, 9, 512]           1,024\n",
      "          Linear-132           [-1, 9, 9, 2048]       1,050,624\n",
      "            GELU-133           [-1, 9, 9, 2048]               0\n",
      "          Linear-134            [-1, 9, 9, 512]       1,049,088\n",
      "        DropPath-135            [-1, 512, 9, 9]               0\n",
      "spectral_ConvBlock-136            [-1, 512, 9, 9]               0\n",
      "       LayerNorm-137            [-1, 512, 9, 9]           1,024\n",
      "            GELU-138            [-1, 512, 9, 9]               0\n",
      "          Linear-139                   [-1, 16]           8,208\n",
      "================================================================\n",
      "Total params: 13,114,320\n",
      "Trainable params: 13,114,320\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.06\n",
      "Forward/backward pass size (MB): 37.30\n",
      "Params size (MB): 50.03\n",
      "Estimated Total Size (MB): 87.39\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "torchsummary.summary(model,(200, 9, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a87075",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "txy_pytorch",
   "language": "python",
   "name": "issactan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
